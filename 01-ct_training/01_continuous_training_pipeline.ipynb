{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8078c471-8ccc-44a9-80de-6be9d56e80a6",
   "metadata": {},
   "source": [
    "# Build a pipeline for continuous model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df378914-5824-4c51-b3e8-4e2731e9b1ba",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "The following steps cover this process:\n",
    "\n",
    "1. Acquire and prepare dataset in BigQuery.\n",
    "2. Create and upload a custom training package. When executed, it reads data from the dataset and trains the model.\n",
    "3. Build a Vertex AI Pipeline. This pipeline executes the custom training package, uploads the model to the Vertex AI Model Registry, runs the evaluation job, and sends an email notification.\n",
    "4. Manually run the pipeline.\n",
    "5. Create a Cloud Function with an Eventarc trigger that runs the pipeline whenever new data is inserted into the BigQuery dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7327e2a5-e6fb-47cb-8a15-dfb6bf595b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/mlops-w-vertex-ai/01-ct_training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb91dbea-f975-4ad2-a50d-37a4f6c0f551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiplatform SDK version: 1.71.0\n",
      "bigquery SDK version: 3.25.0\n",
      "KFP SDK version: 2.7.0\n",
      "google_cloud_pipeline_components version: 2.17.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"from google.cloud import aiplatform; print('aiplatform SDK version: {}'.format(aiplatform.__version__))\"\n",
    "! python3 -c \"from google.cloud import bigquery; print('bigquery SDK version: {}'.format(bigquery.__version__))\"\n",
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0d490b6-b495-4cc9-8fe2-bfc35e28985d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERSION = \"v9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b873185d-9626-4e29-b600-9bb4bbbc2430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiplatform SDK version: 1.71.0\n",
      "bigquery SDK version: 3.25.0\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "print(f'aiplatform SDK version: {aiplatform.__version__}')\n",
    "print(f'bigquery SDK version: {bigquery.__version__}')\n",
    "\n",
    "PROJECT_ID = \"hybrid-vertex\"\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = f\"ct-pipeline-{VERSION}\"\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "\n",
    "bq_client = bigquery.Client(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION\n",
    ")\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8141878-ee6b-49da-ae77-9ab40fb180e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://ct-pipeline-v9/...\n"
     ]
    }
   ],
   "source": [
    "! gcloud storage buckets create $BUCKET_URI --location=$REGION --project=$PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5df7ee-e656-4668-9ad2-209b0e0533ec",
   "metadata": {},
   "source": [
    "# Custom training package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf74b6ee-ca7b-411d-883d-f63008ca3d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !tree training_package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20112fe-c788-4e59-9334-812f6fecf338",
   "metadata": {},
   "source": [
    "### training package directory\n",
    "\n",
    "```\n",
    "training_package\n",
    "├── __init__.py\n",
    "├── setup.py\n",
    "└── trainer\n",
    "    ├── __init__.py\n",
    "    └── task.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e339f-e641-4940-a642-115aa0b5d21b",
   "metadata": {},
   "source": [
    "Run `setup.py` to create source distribution for training app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "889ef356-a420-45c6-93be-d7e9012e964e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to trainer.egg-info/dependency_links.txt\n",
      "writing requirements to trainer.egg-info/requires.txt\n",
      "writing top-level names to trainer.egg-info/top_level.txt\n",
      "reading manifest file 'trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'trainer.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating trainer-0.1\n",
      "creating trainer-0.1/trainer\n",
      "creating trainer-0.1/trainer.egg-info\n",
      "creating trainer-0.1/trainer.egg-info/.ipynb_checkpoints\n",
      "copying files to trainer-0.1...\n",
      "copying README.md -> trainer-0.1\n",
      "copying setup.py -> trainer-0.1\n",
      "copying trainer/__init__.py -> trainer-0.1/trainer\n",
      "copying trainer/task.py -> trainer-0.1/trainer\n",
      "copying trainer.egg-info/PKG-INFO -> trainer-0.1/trainer.egg-info\n",
      "copying trainer.egg-info/SOURCES.txt -> trainer-0.1/trainer.egg-info\n",
      "copying trainer.egg-info/dependency_links.txt -> trainer-0.1/trainer.egg-info\n",
      "copying trainer.egg-info/requires.txt -> trainer-0.1/trainer.egg-info\n",
      "copying trainer.egg-info/top_level.txt -> trainer-0.1/trainer.egg-info\n",
      "copying trainer.egg-info/.ipynb_checkpoints/PKG-INFO-checkpoint -> trainer-0.1/trainer.egg-info/.ipynb_checkpoints\n",
      "copying trainer.egg-info/.ipynb_checkpoints/SOURCES-checkpoint.txt -> trainer-0.1/trainer.egg-info/.ipynb_checkpoints\n",
      "copying trainer.egg-info/.ipynb_checkpoints/dependency_links-checkpoint.txt -> trainer-0.1/trainer.egg-info/.ipynb_checkpoints\n",
      "copying trainer.egg-info/.ipynb_checkpoints/requires-checkpoint.txt -> trainer-0.1/trainer.egg-info/.ipynb_checkpoints\n",
      "copying trainer.egg-info/.ipynb_checkpoints/top_level-checkpoint.txt -> trainer-0.1/trainer.egg-info/.ipynb_checkpoints\n",
      "copying trainer.egg-info/SOURCES.txt -> trainer-0.1/trainer.egg-info\n",
      "Writing trainer-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'trainer-0.1' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "! cd training_package && python setup.py sdist --formats=gztar && cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f637340-95bd-40ec-abbc-80165ba87c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DISTRIBUTION_NAME = \"trainer-0.1.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eae4aafc-aee6-4859-8931-44231c8f3f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://training_package/dist/trainer-0.1.tar.gz to gs://ct-pipeline-v9/trainer-0.1.tar.gz\n",
      "  Completed files 1/1 | 3.8kiB/3.8kiB                                          \n"
     ]
    }
   ],
   "source": [
    "# ! gcloud storage cp training_package/dist/trainer-0.2.tar.gz $BUCKET_URI/\n",
    "! gcloud storage cp training_package/dist/$DISTRIBUTION_NAME $BUCKET_URI/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddeb395-f32d-45a9-b161-dc298f2ad808",
   "metadata": {},
   "source": [
    "# Vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f9387b2-b254-416c-ad19-0d3d9b8cbab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME   : training-v9\n",
      "RUN_NAME          : run-20250114-041128\n",
      "\n",
      "CHECKPT_DIR       : gs://ct-pipeline-v9/training-v9/chkpoint\n",
      "BASE_OUTPUT_DIR   : gs://ct-pipeline-v9/training-v9/run-20250114-041128\n",
      "LOG_DIR           : gs://ct-pipeline-v9/training-v9/run-20250114-041128/logs\n",
      "DATA_DIR          : gs://ct-pipeline-v9/training-v9/run-20250114-041128/data\n",
      "ARTIFACTS_DIR     : gs://ct-pipeline-v9/training-v9/run-20250114-041128/artifacts\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME   = f'training-{VERSION}'\n",
    "\n",
    "# new experiment\n",
    "invoke_time       = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME          = f'run-{invoke_time}'\n",
    "\n",
    "CHECKPT_DIR       = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/chkpoint\"\n",
    "BASE_OUTPUT_DIR   = f\"{BUCKET_URI}/{EXPERIMENT_NAME}/{RUN_NAME}\"\n",
    "LOG_DIR           = f\"{BASE_OUTPUT_DIR}/logs\"\n",
    "DATA_DIR          = f\"{BASE_OUTPUT_DIR}/data\"\n",
    "ARTIFACTS_DIR     = f\"{BASE_OUTPUT_DIR}/artifacts\"\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    staging_bucket=BUCKET_URI,\n",
    "    location=REGION,\n",
    "    # experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "# aiplatform.autolog()\n",
    "\n",
    "print(f\"EXPERIMENT_NAME   : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME          : {RUN_NAME}\\n\")\n",
    "print(f\"CHECKPT_DIR       : {CHECKPT_DIR}\")\n",
    "print(f\"BASE_OUTPUT_DIR   : {BASE_OUTPUT_DIR}\")\n",
    "print(f\"LOG_DIR           : {LOG_DIR}\")\n",
    "print(f\"DATA_DIR          : {DATA_DIR}\")\n",
    "print(f\"ARTIFACTS_DIR     : {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "000602fb-6844-4525-860b-5fc675e06efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ct-pipeline-v9/training-v9/run-20250114-041128/artifacts/\n",
      "gs://ct-pipeline-v9/training-v9/run-20250114-041128/data/\n"
     ]
    }
   ],
   "source": [
    "! gsutil -q cp requirements.txt $ARTIFACTS_DIR/requirements.txt\n",
    "! gsutil -q cp requirements.txt $DATA_DIR/requirements.txt\n",
    "\n",
    "! gsutil ls $BASE_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a92f4-beae-4900-943e-9effb9b902e2",
   "metadata": {},
   "source": [
    "# Vertex Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a79776c0-cf41-4748-a157-1d2aa72ebe5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_ROOT : gs://ct-pipeline-v9/pipeline_root/chicago-taxi-pipe\n",
      "WORKING_DIR   : gs://ct-pipeline-v9/pipeline_root/chicago-taxi-pipe/mlops-trigger-tutorial\n",
      "PIPELINE_NAME : ct-training-v9\n",
      "PIPELINE_FILE : ct-training-v9.yaml\n"
     ]
    }
   ],
   "source": [
    "EMAIL_RECIPIENTS = [ \"jordantotten@google.com\" ]\n",
    "\n",
    "PIPELINE_ROOT = f\"{BUCKET_URI}/pipeline_root/chicago-taxi-pipe\"\n",
    "WORKING_DIR = f\"{PIPELINE_ROOT}/mlops-trigger-tutorial\"\n",
    "os.environ['AIP_MODEL_DIR'] = ARTIFACTS_DIR\n",
    "\n",
    "PIPELINE_NAME = f\"ct-training-{VERSION}\"\n",
    "PIPELINE_FILE = f\"{PIPELINE_NAME}.yaml\"\n",
    "\n",
    "print(f\"PIPELINE_ROOT : {PIPELINE_ROOT}\")\n",
    "print(f\"WORKING_DIR   : {WORKING_DIR}\")\n",
    "print(f\"PIPELINE_NAME : {PIPELINE_NAME}\")\n",
    "print(f\"PIPELINE_FILE : {PIPELINE_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aececbf0-4c47-430f-9e16-1debf4b73e77",
   "metadata": {},
   "source": [
    "## Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba7d8a83-c0ad-4c5a-b250-8cc8f997d684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp.dsl import importer\n",
    "from kfp.dsl import OneOf\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "from google_cloud_pipeline_components.preview.model_evaluation.model_evaluation_import_component import model_evaluation_import as ModelImportEvaluationOp\n",
    "from google_cloud_pipeline_components.v1.custom_job import CustomTrainingJobOp\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "from google_cloud_pipeline_components.v1.batch_predict_job import ModelBatchPredictOp\n",
    "from google_cloud_pipeline_components.v1.model_evaluation import ModelEvaluationRegressionOp\n",
    "from google_cloud_pipeline_components.v1.vertex_notification_email import VertexNotificationEmailOp\n",
    "from google_cloud_pipeline_components.v1.endpoint import ModelDeployOp\n",
    "from google_cloud_pipeline_components.v1.endpoint import EndpointCreateOp\n",
    "\n",
    "# from src.upload_version_component import create_next_model_version\n",
    "\n",
    "# define the train-deploy pipeline\n",
    "@dsl.pipeline(name=PIPELINE_NAME)\n",
    "def custom_model_training_evaluation_pipeline(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    training_job_display_name: str,\n",
    "    worker_pool_specs: list,\n",
    "    base_output_dir: str,\n",
    "    artifacts_dir: str,\n",
    "    prediction_container_uri: str,\n",
    "    model_display_name: str,\n",
    "    batch_prediction_job_display_name: str,\n",
    "    target_field_name: str,\n",
    "    test_data_gcs_uri: list,\n",
    "    ground_truth_gcs_source: list,\n",
    "    batch_predictions_gcs_prefix: str,\n",
    "    eval_display_name: str,\n",
    "    batch_predictions_input_format: str=\"csv\",\n",
    "    batch_predictions_output_format: str=\"jsonl\",\n",
    "    ground_truth_format: str=\"csv\",\n",
    "    parent_model_resource_name: str=None,\n",
    "    parent_model_artifact_uri: str=None,\n",
    "    endpoint_resource_name: str=None,\n",
    "    endpoint_resource_uri: str=None,\n",
    "    existing_model: bool=False,\n",
    "    existing_endpoint: bool=False,\n",
    "    model_version_alias: str=\"new-version\",\n",
    "):\n",
    "    # Notification task\n",
    "    notify_task = VertexNotificationEmailOp(\n",
    "        recipients= EMAIL_RECIPIENTS\n",
    "    )\n",
    "    \n",
    "    with dsl.ExitHandler(notify_task, name='MLOps Continuous Training Pipeline'):\n",
    "        # Train the model\n",
    "        custom_job_task = (\n",
    "            CustomTrainingJobOp(\n",
    "                project=project,\n",
    "                display_name=training_job_display_name,\n",
    "                worker_pool_specs=worker_pool_specs,\n",
    "                base_output_directory=base_output_dir,\n",
    "                location=location\n",
    "            )\n",
    "        ).set_display_name(\"custom-train\")\n",
    "\n",
    "        # Import the unmanaged model\n",
    "        import_unmanaged_model_task = (\n",
    "            importer(\n",
    "                artifact_uri=artifacts_dir,\n",
    "                artifact_class=artifact_types.UnmanagedContainerModel,\n",
    "                metadata={\n",
    "                    \"containerSpec\": {\n",
    "                        \"imageUri\": prediction_container_uri,\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "            .set_display_name(\"import-trained-model\")\n",
    "            .after(custom_job_task)\n",
    "        )\n",
    "\n",
    "        with dsl.If(existing_model == True):\n",
    "            # Import the parent model to upload as a version\n",
    "            import_registry_model_task = (\n",
    "                importer(\n",
    "                    artifact_uri=parent_model_artifact_uri,\n",
    "                    artifact_class=artifact_types.VertexModel,\n",
    "                    metadata={\n",
    "                        \"resourceName\": parent_model_resource_name\n",
    "                    },\n",
    "                )\n",
    "                .set_display_name(\"import-existing-model\")\n",
    "                .after(import_unmanaged_model_task)\n",
    "            )\n",
    "            \n",
    "            # Upload the model as a version\n",
    "            model_version_upload_op = ModelUploadOp(\n",
    "                project=project,\n",
    "                location=location,\n",
    "                display_name=model_display_name,\n",
    "                parent_model=import_registry_model_task.outputs[\"artifact\"],\n",
    "                unmanaged_container_model=import_unmanaged_model_task.outputs[\"artifact\"],\n",
    "            )\n",
    "\n",
    "        with dsl.Else():\n",
    "            # Upload the model\n",
    "            model_upload_op = (\n",
    "                ModelUploadOp(\n",
    "                    project=project,\n",
    "                    location=location,\n",
    "                    display_name=model_display_name,\n",
    "                    unmanaged_container_model=import_unmanaged_model_task.outputs[\"artifact\"],\n",
    "                )\n",
    "                .set_display_name(\"upload-new-model\")\n",
    "            )\n",
    "        \n",
    "        # Get the model (or model version)\n",
    "        model_resource = OneOf(\n",
    "                model_version_upload_op.outputs[\"model\"], \n",
    "                model_upload_op.outputs[\"model\"]\n",
    "        )\n",
    "\n",
    "        # Batch prediction\n",
    "        batch_predict_task = (\n",
    "            ModelBatchPredictOp(\n",
    "                project=project,\n",
    "                job_display_name=batch_prediction_job_display_name,\n",
    "                model=model_resource,\n",
    "                location=location,\n",
    "                instances_format=batch_predictions_input_format,\n",
    "                predictions_format=batch_predictions_output_format,\n",
    "                gcs_source_uris=test_data_gcs_uri,\n",
    "                gcs_destination_output_uri_prefix=batch_predictions_gcs_prefix,\n",
    "                machine_type='n1-standard-4'\n",
    "            )\n",
    "            .set_display_name(\"batch-prediction\")\n",
    "        )\n",
    "        \n",
    "        # Evaluation task\n",
    "        evaluation_task = (\n",
    "            ModelEvaluationRegressionOp(\n",
    "                project=project,\n",
    "                target_field_name=target_field_name,\n",
    "                location=location,\n",
    "                model=model_resource,\n",
    "                predictions_format=batch_predictions_output_format,\n",
    "                predictions_gcs_source=batch_predict_task.outputs[\"gcs_output_directory\"],\n",
    "                ground_truth_format=ground_truth_format,\n",
    "                ground_truth_gcs_source=ground_truth_gcs_source\n",
    "            )\n",
    "            .set_display_name(\"model-eval-job\")\n",
    "        )\n",
    "        \n",
    "        # Import the evaluation result to Vertex AI.\n",
    "        import_evaluation_task = (\n",
    "            ModelImportEvaluationOp(\n",
    "                regression_metrics=evaluation_task.outputs['evaluation_metrics'],\n",
    "                model=model_resource,\n",
    "                dataset_type=batch_predictions_input_format,\n",
    "                dataset_path=\"\", # test_data_gcs_uri\n",
    "                dataset_paths=ground_truth_gcs_source,\n",
    "                display_name=eval_display_name,\n",
    "            )\n",
    "            .set_display_name(\"import-model-eval\")\n",
    "        )\n",
    "        \n",
    "        \n",
    "        with dsl.If(existing_endpoint == True):\n",
    "            # Import the parent model to upload as a version\n",
    "            endpoint = importer(\n",
    "                artifact_uri=endpoint_resource_uri,\n",
    "                artifact_class=artifact_types.VertexEndpoint,\n",
    "                metadata={\"resourceName\": endpoint_resource_name},\n",
    "            )\n",
    "            \n",
    "            # deploy model to endpoint\n",
    "            _ = ModelDeployOp(\n",
    "                model=model_resource,\n",
    "                endpoint=endpoint.output,  # .outputs[\"endpoint\"],\n",
    "                dedicated_resources_min_replica_count=1,\n",
    "                dedicated_resources_max_replica_count=1,\n",
    "                dedicated_resources_machine_type=\"n1-standard-4\",\n",
    "                traffic_split={\"0\": 100},\n",
    "            )\n",
    "            \n",
    "        with dsl.Else():\n",
    "            # Create an endpoint\n",
    "            endpoint_create_op = EndpointCreateOp(\n",
    "                project=project,\n",
    "                display_name=\"taxifare-endpoint\",\n",
    "            )\n",
    "            # deploy model to endpoint\n",
    "            _ = ModelDeployOp(\n",
    "                model=model_resource,\n",
    "                endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "                dedicated_resources_min_replica_count=1,\n",
    "                dedicated_resources_max_replica_count=1,\n",
    "                dedicated_resources_machine_type=\"n1-standard-4\",\n",
    "                traffic_split={\"0\": 100},\n",
    "            )\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29db62-fd0f-48d0-9be1-63ae6ac42e2a",
   "metadata": {},
   "source": [
    "## Compile pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06d49c05-599e-4f24-ac12-47032c63e793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL_PIPELINE_YAML: ct-training-v9.yaml\n"
     ]
    }
   ],
   "source": [
    "from kfp import dsl\n",
    "from kfp import compiler\n",
    "from kfp.registry import RegistryClient\n",
    "\n",
    "LOCAL_PIPELINE_YAML = PIPELINE_FILE\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=custom_model_training_evaluation_pipeline,\n",
    "    package_path=LOCAL_PIPELINE_YAML,\n",
    "    # package_path=\"{}.yaml\".format(PIPELINE_NAME),\n",
    ")\n",
    "\n",
    "print(f\"LOCAL_PIPELINE_YAML: {LOCAL_PIPELINE_YAML}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f769fc7-d438-479a-bcaf-bd7c5de2820c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ct-pipeline-v9/training-v9/run-20250114-041128/ct-training-v9.yaml\n",
      "gs://ct-pipeline-v9/training-v9/run-20250114-041128/artifacts/\n",
      "gs://ct-pipeline-v9/training-v9/run-20250114-041128/data/\n"
     ]
    }
   ],
   "source": [
    "! gsutil -q cp $LOCAL_PIPELINE_YAML $BASE_OUTPUT_DIR/$LOCAL_PIPELINE_YAML\n",
    "\n",
    "! gsutil ls $BASE_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20bd99a-8710-4146-b020-4ef616c6fa1b",
   "metadata": {},
   "source": [
    "## Upload as pipeline template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a364fdb4-ae1e-4d3b-8ffa-de586cbba84a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPLATE_NAME : ct-training-v9\n",
      "TEMPLATE_URI  : https://us-central1-kfp.pkg.dev/hybrid-vertex/mlops/ct-training-v9/latest\n"
     ]
    }
   ],
   "source": [
    "REPO_NAME = \"mlops\"\n",
    "\n",
    "# Create a repo in the artifact registry\n",
    "# ! gcloud artifacts repositories create $REPO_NAME --location=$REGION --repository-format=KFP\n",
    "\n",
    "host = f\"https://{REGION}-kfp.pkg.dev/{PROJECT_ID}/{REPO_NAME}\"\n",
    "client = RegistryClient(host=host)\n",
    "\n",
    "TEMPLATE_NAME, VERSION_NAME = client.upload_pipeline(\n",
    "    file_name=PIPELINE_FILE,\n",
    "    tags=[VERSION, \"latest\"],\n",
    "    extra_headers={\"description\":\"This is an example pipeline template.\"}\n",
    ")\n",
    "\n",
    "TEMPLATE_URI = f\"https://{REGION}-kfp.pkg.dev/{PROJECT_ID}/{REPO_NAME}/{TEMPLATE_NAME}/latest\"\n",
    "\n",
    "print(f\"TEMPLATE_NAME : {TEMPLATE_NAME}\")\n",
    "print(f\"TEMPLATE_URI  : {TEMPLATE_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07246e56-5fb0-48e2-a7f2-8868a1a493d4",
   "metadata": {},
   "source": [
    "# Manually Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de69d5d-2d28-45d2-9155-34d32983e724",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1fb70b4-8512-41da-b81d-86f55ba35ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'machine_spec': {'machine_type': 'e2-highmem-16'},\n",
      "  'python_package_spec': {'args': ['--project-id',\n",
      "                                   'hybrid-vertex',\n",
      "                                   '--data-dir',\n",
      "                                   '/gcs/ct-pipeline-v9/training-v9/run-20250114-041128/data',\n",
      "                                   '--training-dir',\n",
      "                                   '/gcs/ct-pipeline-v9/training-v9/run-20250114-041128/artifacts',\n",
      "                                   '--bq-source',\n",
      "                                   'hybrid-vertex.mlops.chicago',\n",
      "                                   '--experiment-run',\n",
      "                                   'run-20250114-041128',\n",
      "                                   '--experiment-name',\n",
      "                                   'training-v9'],\n",
      "                          'executor_image_uri': 'us-docker.pkg.dev/vertex-ai/training/sklearn-cpu.1-0:latest',\n",
      "                          'package_uris': ['gs://ct-pipeline-v9/trainer-0.1.tar.gz'],\n",
      "                          'python_module': 'trainer.task'},\n",
      "  'replica_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"mlops\"\n",
    "TABLE_NAME = \"chicago\"\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\"machine_type\": \"e2-highmem-16\"},\n",
    "        \"replica_count\": 1,\n",
    "        \"python_package_spec\": {\n",
    "            \"executor_image_uri\": \"us-docker.pkg.dev/vertex-ai/training/sklearn-cpu.1-0:latest\",\n",
    "            \"package_uris\": [f\"{BUCKET_URI}/{DISTRIBUTION_NAME}\"],\n",
    "            \"python_module\": \"trainer.task\",\n",
    "            \"args\":[\n",
    "                \"--project-id\", PROJECT_ID,\n",
    "                \"--data-dir\", f\"/gcs/{BUCKET_NAME}/{EXPERIMENT_NAME}/{RUN_NAME}/data\",\n",
    "                \"--training-dir\", f\"/gcs/{BUCKET_NAME}/{EXPERIMENT_NAME}/{RUN_NAME}/artifacts\",\n",
    "                \"--bq-source\", f\"{PROJECT_ID}.{DATASET_NAME}.{TABLE_NAME}\",\n",
    "                \"--experiment-run\", RUN_NAME,\n",
    "                \"--experiment-name\", EXPERIMENT_NAME,\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    "]\n",
    "pprint(worker_pool_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9120e09-5796-4a34-a3c2-aceab5e6c20a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# existing model\n",
    "EXISTING_MODEL_BOOL=True # True | False\n",
    "PARENT_MODEL_ID=\"3204070341827624960\"\n",
    "PARENT_MODEL_URI=\"gs://ct-pipeline-v6/training-v6/run-20241105-160557/artifacts\"\n",
    "MODEL_VERSION_ALIAS=\"v4\"\n",
    "\n",
    "# endpoint\n",
    "EXISTING_ENDPOINT_BOOL=True\n",
    "ENDPOINT_ID=\"3326806625813004288\"\n",
    "ENDPOINT_RESOURCE_NAME=f\"projects/934903580331/locations/{REGION}/endpoints/{ENDPOINT_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e0b7140-890a-47ad-aa08-7bdc31cac914",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artifacts_dir': 'gs://ct-pipeline-v9/training-v9/run-20250114-041128/artifacts',\n",
      " 'base_output_dir': 'gs://ct-pipeline-v9/training-v9/run-20250114-041128',\n",
      " 'batch_prediction_job_display_name': 'taxifare-prediction-batch-job',\n",
      " 'batch_predictions_gcs_prefix': 'gs://ct-pipeline-v9/batch_predict_output',\n",
      " 'endpoint_resource_name': 'projects/934903580331/locations/us-central1/endpoints/3326806625813004288',\n",
      " 'endpoint_resource_uri': 'https://us-central1-aiplatform.googleapis.com/v1/projects/934903580331/locations/us-central1/endpoints/3326806625813004288',\n",
      " 'eval_display_name': 'eval-20250114-041128',\n",
      " 'existing_endpoint': True,\n",
      " 'existing_model': True,\n",
      " 'ground_truth_gcs_source': ['gs://ct-pipeline-v9/training-v9/run-20250114-041128/data/test.csv'],\n",
      " 'location': 'us-central1',\n",
      " 'model_display_name': 'taxifare-prediction-model',\n",
      " 'model_version_alias': 'v4',\n",
      " 'parent_model_artifact_uri': 'gs://ct-pipeline-v6/training-v6/run-20241105-160557/artifacts',\n",
      " 'parent_model_resource_name': 'projects/hybrid-vertex/locations/us-central1/models/3204070341827624960',\n",
      " 'prediction_container_uri': 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest',\n",
      " 'project': 'hybrid-vertex',\n",
      " 'target_field_name': 'fare',\n",
      " 'test_data_gcs_uri': ['gs://ct-pipeline-v9/training-v9/run-20250114-041128/data/test_no_target.csv'],\n",
      " 'training_job_display_name': 'taxifare-prediction-training-job',\n",
      " 'version': 'v9',\n",
      " 'worker_pool_specs': [{'machine_spec': {'machine_type': 'e2-highmem-16'},\n",
      "                        'python_package_spec': {'args': ['--project-id',\n",
      "                                                         'hybrid-vertex',\n",
      "                                                         '--data-dir',\n",
      "                                                         '/gcs/ct-pipeline-v9/training-v9/run-20250114-041128/data',\n",
      "                                                         '--training-dir',\n",
      "                                                         '/gcs/ct-pipeline-v9/training-v9/run-20250114-041128/artifacts',\n",
      "                                                         '--bq-source',\n",
      "                                                         'hybrid-vertex.mlops.chicago',\n",
      "                                                         '--experiment-run',\n",
      "                                                         'run-20250114-041128',\n",
      "                                                         '--experiment-name',\n",
      "                                                         'training-v9'],\n",
      "                                                'executor_image_uri': 'us-docker.pkg.dev/vertex-ai/training/sklearn-cpu.1-0:latest',\n",
      "                                                'package_uris': ['gs://ct-pipeline-v9/trainer-0.1.tar.gz'],\n",
      "                                                'python_module': 'trainer.task'},\n",
      "                        'replica_count': 1}]}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"location\": REGION,\n",
    "    \"version\": VERSION,\n",
    "    \"training_job_display_name\": \"taxifare-prediction-training-job\",\n",
    "    \"worker_pool_specs\": worker_pool_specs,\n",
    "    \"base_output_dir\": BASE_OUTPUT_DIR,\n",
    "    \"artifacts_dir\": ARTIFACTS_DIR,\n",
    "    \"prediction_container_uri\": \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\",\n",
    "    \"model_display_name\": \"taxifare-prediction-model\",\n",
    "    \"batch_prediction_job_display_name\": \"taxifare-prediction-batch-job\",\n",
    "    \"target_field_name\": \"fare\",\n",
    "    \"test_data_gcs_uri\": [f\"{DATA_DIR}/test_no_target.csv\"],\n",
    "    \"ground_truth_gcs_source\": [f\"{DATA_DIR}/test.csv\"],\n",
    "    \"batch_predictions_gcs_prefix\": f\"{BUCKET_URI}/batch_predict_output\",\n",
    "    \"eval_display_name\": f'eval-{invoke_time}',\n",
    "    \"existing_model\": EXISTING_MODEL_BOOL,\n",
    "    \"existing_endpoint\":EXISTING_ENDPOINT_BOOL,\n",
    "}\n",
    "\n",
    "if EXISTING_MODEL_BOOL:\n",
    "    parameters[\"parent_model_resource_name\"] = f\"projects/{PROJECT_ID}/locations/{REGION}/models/{PARENT_MODEL_ID}\"\n",
    "    parameters[\"parent_model_artifact_uri\"] = PARENT_MODEL_URI\n",
    "    parameters[\"model_version_alias\"] = MODEL_VERSION_ALIAS\n",
    "    \n",
    "    \n",
    "if EXISTING_ENDPOINT_BOOL:\n",
    "    parameters[\"endpoint_resource_uri\"] = f\"https://us-central1-aiplatform.googleapis.com/v1/{ENDPOINT_RESOURCE_NAME}\"\n",
    "    parameters[\"endpoint_resource_name\"] = ENDPOINT_RESOURCE_NAME\n",
    "\n",
    "\n",
    "pprint(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc9777-a3d3-42c6-b5f2-38d61d98aa19",
   "metadata": {},
   "source": [
    "## Create and Run pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2300652f-3ae0-4fdf-abd0-a380560b8597",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/934903580331/locations/us-central1/pipelineJobs/ct-training-v9-20250114041203\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/934903580331/locations/us-central1/pipelineJobs/ct-training-v9-20250114041203')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/ct-training-v9-20250114041203?project=934903580331\n",
      "Associating projects/934903580331/locations/us-central1/pipelineJobs/ct-training-v9-20250114041203 to Experiment: training-v9\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline job\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=f\"{PIPELINE_NAME}-manual\",\n",
    "    template_path=TEMPLATE_URI,\n",
    "    parameter_values=parameters,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    enable_caching=False,\n",
    "    failure_policy='fast',\n",
    ")\n",
    "# Run the pipeline job\n",
    "# job.run(sync=False)\n",
    "\n",
    "job.submit(\n",
    "    experiment=EXPERIMENT_NAME,\n",
    "    # service_account=\"934903580331-compute@developer.gserviceaccount.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5405c71f-54c3-4fb9-a136-f66fbdeab74d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inspect deployed models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e39714-1e20-4e2c-805d-ab90e6fed294",
   "metadata": {},
   "source": [
    "### initialize Model resource\n",
    "\n",
    "* `model_name`: Required. fully-qualified model resource name or model ID\n",
    "* `version`: Optional. Version ID or version alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82879364-69fb-4f3a-87e3-76b066f46f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Model object at 0x7f2edc707880> \n",
       "resource name: projects/934903580331/locations/us-central1/models/3204070341827624960"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = aiplatform.Model(\n",
    "    model_name=\"projects/934903580331/locations/us-central1/models/3204070341827624960\", #@2\n",
    "    version=\"2\",\n",
    ")\n",
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "027a0eb1-f001-4de5-905e-005e398912d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/934903580331/locations/us-central1/models/3204070341827624960',\n",
       " 'displayName': 'taxifare-prediction-model',\n",
       " 'predictSchemata': {},\n",
       " 'metadata': None,\n",
       " 'containerSpec': {'imageUri': 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest'},\n",
       " 'supportedDeploymentResourcesTypes': ['DEDICATED_RESOURCES'],\n",
       " 'supportedInputStorageFormats': ['jsonl',\n",
       "  'bigquery',\n",
       "  'csv',\n",
       "  'tf-record',\n",
       "  'tf-record-gzip',\n",
       "  'file-list'],\n",
       " 'supportedOutputStorageFormats': ['jsonl', 'bigquery'],\n",
       " 'createTime': '2024-11-05T16:09:47.035941Z',\n",
       " 'updateTime': '2024-11-07T16:59:21.266241Z',\n",
       " 'etag': 'AMEw9yObdsIU2rg2_jZeADdcn4DPEA2pydpeB3j4glon7em9gRCVpacPOa1pxId6nog=',\n",
       " 'labels': {'vertex-ai-pipelines-run-billing-id': '9056019495159595008'},\n",
       " 'supportedExportFormats': [{'id': 'custom-trained',\n",
       "   'exportableContents': ['ARTIFACT']}],\n",
       " 'artifactUri': 'gs://ct-pipeline-v6/training-v6/run-20241105-160557/artifacts',\n",
       " 'versionId': '1',\n",
       " 'versionAliases': ['default'],\n",
       " 'versionCreateTime': '2024-11-05T16:09:47.035941Z',\n",
       " 'versionUpdateTime': '2024-11-05T16:09:49.240787Z',\n",
       " 'modelSourceInfo': {'sourceType': 'CUSTOM'}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d217ad78-a8b2-463d-9fb3-278a0806adfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<google.cloud.aiplatform.model_evaluation.model_evaluation.ModelEvaluation object at 0x7f2edc705fc0> \n",
       " resource name: projects/934903580331/locations/us-central1/models/3204070341827624960@1/evaluations/3761886780687585792]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_evaluations = my_model.list_model_evaluations()\n",
    "my_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ae9eff7-de42-44cf-b5db-9c3f6b9c7992",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/934903580331/locations/us-central1/models/7404802894257455104'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a946ba-cbab-4f7b-9b58-b3a00c984d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_ID = \"3326806625813004288\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d2da4-7edb-4df0-8a6c-251949eea80c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create model evaluation job (SDK)\n",
    "\n",
    "> see [code snippets](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_evaluation/custom_tabular_regression_model_evaluation.ipynb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239aa67b-8543-4d02-bbc0-d72166f36bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile instance_schema.yaml\n",
    "title: TabularRegression\n",
    "description: 'Regression Instances.'\n",
    "\n",
    "type: object\n",
    "properties:\n",
    "  dense_input:\n",
    "    type: array\n",
    "    items:\n",
    "      type: float\n",
    "      minimum: 0.0\n",
    "      maximum: 1.0\n",
    "    description: 'Input values to model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ccc53-1964-4900-8989-10d0188d24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile prediction_schema.yaml\n",
    "title: TabularRegression\n",
    "description: 'Regression results.'\n",
    "\n",
    "type: array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d5f67-274b-4f1a-a6fe-c6017a26be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp instance_schema.yaml {BUCKET_URI}/instance_schema.yaml\n",
    "!gsutil cp prediction_schema.yaml {BUCKET_URI}/prediction_schema.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2839768-5826-4ae5-84e4-ef9bcc371f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## upload to Registy\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=\"boston_new_model\",\n",
    "    artifact_uri=MODEL_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    instance_schema_uri=f\"{BUCKET_URI}/instance_schema.yaml\",\n",
    "    prediction_schema_uri=f\"{BUCKET_URI}/prediction_schema.yaml\",\n",
    "    explanation_parameters=parameters,\n",
    "    explanation_metadata=metadata,\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0729eb-1fcf-49db-bfe3-ce5e5ad94ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_input_uri = BUCKET_URI + \"/\" + \"test_file_with_ground_truth.jsonl\"\n",
    "with tf.io.gfile.GFile(gcs_input_uri, \"w\") as f:\n",
    "    for i in range(10):\n",
    "        data = {serving_input: x_test[i].tolist(), \"MEDV\": y_test[i]}\n",
    "        f.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f24556-521f-457b-8721-6ba53fb04b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = model.evaluate(\n",
    "    prediction_type=\"regression\",\n",
    "    target_field_name=\"MEDV\",\n",
    "    gcs_source_uris=[BUCKET_URI + \"/\" + \"test_file_with_ground_truth.jsonl\"],\n",
    "    generate_feature_attributions=True,\n",
    ")\n",
    "\n",
    "print(\"Waiting model evaluation is in process\")\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06179a39-c8d1-434b-9dbf-47f82e63387e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cee1448-f81e-4de2-8eea-124803349b7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Associate eval with model (manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05291472-99cd-44bb-8a75-fea5b54ca3c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rootMeanSquaredError': 2.019573, 'rSquared': 0.9765769, 'meanAbsoluteError': 0.7664642, 'meanAbsolutePercentageError': 5.1649256, 'rootMeanSquaredLogError': 0.093754485}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "display_name: \"eval-sdk\"\n",
       "metrics_schema_uri: \"gs://google-cloud-aiplatform/schema/modelevaluation/regression_metrics_1.0.0.yaml\"\n",
       "metrics {\n",
       "  struct_value {\n",
       "    fields {\n",
       "      key: \"rootMeanSquaredLogError\"\n",
       "      value {\n",
       "        number_value: 0.093754485\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"rootMeanSquaredError\"\n",
       "      value {\n",
       "        number_value: 2.019573\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"rSquared\"\n",
       "      value {\n",
       "        number_value: 0.9765769\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"meanAbsolutePercentageError\"\n",
       "      value {\n",
       "        number_value: 5.1649256\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"meanAbsoluteError\"\n",
       "      value {\n",
       "        number_value: 0.7664642\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud.aiplatform import gapic\n",
    "\n",
    "# metrics = {\"logLoss\": 1.4, \"auPrc\": 0.85}\n",
    "# print(metrics)\n",
    "\n",
    "# model_eval = gapic.ModelEvaluation(\n",
    "#     display_name=\"eval\",\n",
    "#     metrics_schema_uri=\"gs://google-cloud-aiplatform/schema/modelevaluation/classification_metrics_1.0.0.yaml\",\n",
    "#     metrics=metrics,\n",
    "# )\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"rootMeanSquaredError\": 2.019573,\n",
    "    \"rSquared\": 0.9765769,\n",
    "    \"meanAbsoluteError\": 0.7664642, \n",
    "    \"meanAbsolutePercentageError\": 5.1649256,\n",
    "    \"rootMeanSquaredLogError\": 0.093754485\n",
    ",\n",
    "}\n",
    "print(metrics)\n",
    "\n",
    "model_eval = gapic.ModelEvaluation(\n",
    "    display_name=\"eval-sdk\",\n",
    "    metrics_schema_uri=\"gs://google-cloud-aiplatform/schema/modelevaluation/regression_metrics_1.0.0.yaml\",\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5271064f-4879-475f-8dcd-644382ec8eaf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Upload the evaluation metrics to the Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "605ffcf4-a3f0-4030-bb51-ce0a9937ac3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform_v1.services.model_service.client.ModelServiceClient at 0x7fce75ddad10>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "client = gapic.ModelServiceClient(client_options={\"api_endpoint\": API_ENDPOINT})\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68d3c861-c41f-4d4e-ac52-e2c401ab64c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/934903580331/locations/us-central1/models/7404802894257455104/evaluations/3687972264888737838\"\n",
       "display_name: \"eval-sdk\"\n",
       "metrics_schema_uri: \"gs://google-cloud-aiplatform/schema/modelevaluation/regression_metrics_1.0.0.yaml\"\n",
       "metrics {\n",
       "  struct_value {\n",
       "    fields {\n",
       "      key: \"rootMeanSquaredLogError\"\n",
       "      value {\n",
       "        number_value: 0.093754485\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"rootMeanSquaredError\"\n",
       "      value {\n",
       "        number_value: 2.019573\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"rSquared\"\n",
       "      value {\n",
       "        number_value: 0.9765769\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"meanAbsolutePercentageError\"\n",
       "      value {\n",
       "        number_value: 5.1649256\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"meanAbsoluteError\"\n",
       "      value {\n",
       "        number_value: 0.7664642\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.import_model_evaluation(parent=my_model.resource_name, model_evaluation=model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06d2fb62-5e87-4887-8ac3-cb500e0efda7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_evaluations = my_model.list_model_evaluations()\n",
    "my_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f1137af-64f4-4284-aec8-75c4b8ec17ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting version 1 info for projects/934903580331/locations/us-central1/models/7404802894257455104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VersionInfo(version_id='1', version_create_time=DatetimeWithNanoseconds(2024, 11, 5, 3, 53, 2, 910944, tzinfo=datetime.timezone.utc), version_update_time=DatetimeWithNanoseconds(2024, 11, 5, 3, 53, 4, 865125, tzinfo=datetime.timezone.utc), model_display_name='taxifare-prediction-model', model_resource_name='projects/934903580331/locations/us-central1/models/7404802894257455104', version_aliases=['default'], version_description='')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_registry = aiplatform.models.ModelRegistry(model=\"projects/934903580331/locations/us-central1/models/7404802894257455104\")\n",
    "model_version_info = model_registry.get_version_info(version=\"1\")\n",
    "model_version_info"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
